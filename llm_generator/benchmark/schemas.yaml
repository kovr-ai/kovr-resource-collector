benchmark:
  prompt_input:
    benchmark_text: string
    benchmark_source: string      # e.g., "OWASP Top 10 2021"
    benchmark_version: string     # e.g., "2021"
    extraction_context: string    # Additional context for LLM
  
  prompt_output:
    checks[]: ./check
    metadata:
      title: string
      description: string
      version: string
      total_checks_extracted: int
      extraction_date: datetime
      benchmark_source: string
      coverage_metrics: ./coverage_metrics

check:
  check_id: string              # Global unique ID format: "OWASP-2021-A01-001"
  title: string                 # Short descriptive name
  description: string           # Targeted and actionable description
  benchmark_source: string      # Source benchmark reference
  
  # Step 2 mapping results
  controls[]: string            # Mapped control IDs: ["NIST-800-53-AC-3"]
  frameworks[]: string          # Framework names: ["NIST-800-53", "ISO-27001"]
  benchmark_mapping[]: string   # Existing benchmark check IDs if any
  mapping_confidence: float     # Confidence score for mappings (0.0-1.0)
  
  # Additional metadata
  category: string              # Check category
  severity: string              # Risk severity level
  tags[]: string               # Classification tags
  
  # Raw extraction metadata
  extracted_at: datetime
  mapped_at: datetime

coverage_metrics:
  total_checks_extracted: int
  mapped_to_controls: int
  mapped_to_existing_benchmarks: int
  unmapped_checks: int
  coverage_percentages:
    extraction: float           # Always 100% for extracted checks
    control_mapping: float      # % of checks mapped to controls
    benchmark_mapping: float    # % mapped to existing benchmarks
  
  # Framework breakdown
  framework_coverage: 
    framework_name: string
    controls_mapped: int
    checks_mapped: int
