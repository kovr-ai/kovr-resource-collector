resource:
  check:
    unique_id: owasp-latest-implement-tokenization-techniques
  field_paths:
  - event_selectors
  - event_selectors[]
  - event_selectors[].data_resources
  - event_selectors[].data_resources.type
  - event_selectors[].data_resources.values
  - event_selectors[].data_resources.values[]
  - event_selectors[].include_management_events
  - event_selectors[].read_write_type
  - trails
  - trails[]
  - trails[].event_selectors
  - trails[].event_selectors[]
  - trails[].event_selectors[].data_resources
  - trails[].event_selectors[].data_resources.type
  - trails[].event_selectors[].data_resources.values
  - trails[].event_selectors[].data_resources.values[]
  - trails[].event_selectors[].include_management_events
  - trails[].event_selectors[].read_write_type
  fix_details:
    automation_available: true
    description: To implement tokenization techniques for protecting sensitive data,
      you need to use dedicated AWS services or third-party solutions designed for
      tokenization.
    estimated_time: 1-2 hours for evaluation and setup, plus ongoing maintenance
    instructions:
    - Identify the sensitive data elements that require tokenization, such as credit
      card numbers, social security numbers, or other PII.
    - Evaluate and select an appropriate tokenization solution, such as AWS Secrets
      Manager, AWS Key Management Service (KMS), or a third-party tokenization service.
    - Configure the tokenization solution to replace sensitive data elements with
      non-sensitive tokens, and store the original sensitive data in a secure token
      vault.
    - Integrate the tokenization solution with your applications and services that
      handle sensitive data.
    - Monitor and audit the tokenization operations using CloudTrail logs.
  is_valid: false
  literature: The AWS CloudTrail resource is used for logging and monitoring API activity
    within an AWS account. It does not directly implement tokenization techniques
    for protecting sensitive data at rest or in transit. Tokenization is a data security
    technique that replaces sensitive data elements with non-sensitive placeholders
    called tokens, typically used for protecting data like credit card numbers, social
    security numbers, and other personally identifiable information (PII). While CloudTrail
    can log API activity related to data encryption and tokenization services, it
    does not directly implement tokenization itself.
  name: CloudTrailResource
  output_statements:
    failure: CloudTrail does not directly implement tokenization techniques for protecting
      sensitive data at rest or in transit.
    partial: CloudTrail can log API activity related to tokenization services, but
      does not directly implement tokenization itself.
    success: CloudTrail is configured to log API activity related to tokenization
      services, enabling monitoring and auditing of tokenization operations.
  reason: The CloudTrail resource is primarily used for logging and monitoring API
    activity, but does not directly implement tokenization techniques for protecting
    sensitive data. Tokenization is a separate data security technique that requires
    dedicated services or solutions.
