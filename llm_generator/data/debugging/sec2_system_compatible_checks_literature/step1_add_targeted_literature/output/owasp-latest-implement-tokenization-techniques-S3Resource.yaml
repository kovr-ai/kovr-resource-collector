resource:
  check:
    unique_id: owasp-latest-implement-tokenization-techniques
  field_paths:
  - buckets[].encryption
  - buckets[].encryption.enabled
  - buckets[].encryption.type
  fix_details:
    automation_available: true
    description: To implement tokenization techniques for sensitive data stored in
      S3 buckets, you need to integrate a tokenization solution at the application
      or data layer.
    estimated_time: 1-2 weeks
    instructions:
    - 1. Identify the sensitive data elements that need to be tokenized (e.g., credit
      card numbers, social security numbers, PII).
    - 2. Evaluate and select a tokenization solution that meets your organization's
      security and compliance requirements.
    - 3. Implement the tokenization solution in your application or data processing
      pipeline.
    - 4. Replace sensitive data elements with tokens before storing or transmitting
      the data to S3 buckets.
    - 5. Store the original sensitive data in a secure token vault, accessible only
      by authorized systems or processes.
    - 6. Implement access controls, auditing, and monitoring for the tokenization
      solution and token vault.
  is_valid: false
  literature: The security check 'owasp-latest-implement-tokenization-techniques'
    focuses on implementing tokenization techniques to protect sensitive data at rest
    and in transit. Tokenization is a data security technique that replaces sensitive
    data elements with non-sensitive placeholders called tokens, which are stored
    in a secure token vault. This helps minimize the exposure of sensitive data and
    reduce the risk of data breaches and unauthorized access.
  name: S3Resource
  output_statements:
    failure: The S3 bucket(s) do not have tokenization techniques implemented to protect
      sensitive data.
    partial: Some S3 buckets have tokenization techniques implemented, while others
      do not.
    success: The S3 bucket(s) have tokenization techniques implemented to protect
      sensitive data.
  reason: The AWS S3 resource provided does not directly support tokenization techniques.
    S3 is an object storage service that allows you to store and retrieve data, but
    it does not have built-in tokenization capabilities. Tokenization is typically
    implemented at the application or data layer, where sensitive data is replaced
    with tokens before being stored or transmitted.
