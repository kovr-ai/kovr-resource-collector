check:
  category: encryption
  control_names:
  - NIST-800-53-SC-28
  - ISO-27001-A.8.2.3
  literature: Tokenization is a data security technique that replaces sensitive data
    elements with non-sensitive placeholders called tokens. This process helps protect
    sensitive data by removing it from the operational environment and storing it
    in a secure token vault. Tokenization is an effective method for meeting data
    security and compliance requirements, as it reduces the risk of data breaches
    and unauthorized access to sensitive information. By implementing tokenization
    techniques, organizations can minimize the exposure of sensitive data, such as
    credit card numbers, social security numbers, and other personally identifiable
    information (PII), while still allowing authorized systems and applications to
    process and use the tokenized data. This check validates that tokenization techniques
    are implemented to protect sensitive data at rest and in transit.
  provider: aws
  resource:
    field_paths:
    - alarms
    - alarms[]
    - alarms[].actions_enabled
    - alarms[].alarm_actions
    - alarms[].alarm_actions[]
    - alarms[].alarm_description
    - alarms[].alarm_name
    - alarms[].comparison_operator
    - alarms[].dimensions
    - alarms[].dimensions[]
    - alarms[].dimensions[].Name
    - alarms[].dimensions[].Value
    - alarms[].evaluation_periods
    - alarms[].insufficient_data_actions
    - alarms[].insufficient_data_actions[]
    - alarms[].metric_name
    - alarms[].namespace
    - alarms[].ok_actions
    - alarms[].ok_actions[]
    - alarms[].period
    - alarms[].state_reason
    - alarms[].state_updated_timestamp
    - alarms[].state_value
    - alarms[].statistic
    - alarms[].threshold
    - dashboards
    - dashboards[]
    - dashboards[].dashboard_arn
    - dashboards[].dashboard_body
    - dashboards[].dashboard_name
    - dashboards[].last_modified
    - dashboards[].size
    - id
    - log_groups
    - log_groups[]
    - log_groups[].arn
    - log_groups[].creation_time
    - log_groups[].id
    - log_groups[].kms_key_id
    - log_groups[].log_group_name
    - log_groups[].metric_filter_count
    - log_groups[].retention_in_days
    - log_groups[].stored_bytes
    - metrics
    - metrics[]
    - metrics[].dimensions
    - metrics[].dimensions[]
    - metrics[].dimensions[].Name
    - metrics[].dimensions[].Value
    - metrics[].metric_name
    - metrics[].namespace
    - source_connector
    name: CloudWatchResource
  unique_id: owasp-latest-implement-tokenization-techniques
